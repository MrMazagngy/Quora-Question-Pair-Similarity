{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "BERT + CNN Quora Quesions Pairs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCmgd1QmPF9t9Vlj4ixN2+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrMazagngy/Quora-Question-Pair-Similarity/blob/main/BERT_%2B_CNN_Quora_Quesions_Pairs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dijXiw7nTJiC"
      },
      "source": [
        " ! pip install -q kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZnxduHuTT-z"
      },
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOvLFhdTTZKF"
      },
      "source": [
        "! mkdir ~/.kaggle \n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh2yvmZYTe59"
      },
      "source": [
        "! kaggle competitions download quora-question-pairs\n",
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo6twrsg83DC"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyieoIl-U0Ws"
      },
      "source": [
        "import pandas as pd\n",
        "import transformers\n",
        "import torch \n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import seaborn as sns \n",
        "import re\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxAjzVTIIFyj"
      },
      "source": [
        "#Vaiables \n",
        "RANDOM_SEED = 2\n",
        "max_length = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hdcv48kEcrQO"
      },
      "source": [
        "#Define the Bert Tokenizer\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9-DRSfkcoDD"
      },
      "source": [
        "#We will only work with the train set due to limited computational power\n",
        "df = pd.read_csv('train.csv')\n",
        "len(df)\n",
        "df = df[-300:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVr9g68ccF24"
      },
      "source": [
        "def preprocess(series):\n",
        "  #remove characters other than alphabets & numerics\n",
        "  words = re.sub(\"[^A-Za-z0-9]\",\" \",str(series)).lower().split()\n",
        "\n",
        "  #lemmatize words\n",
        "  lemm = WordNetLemmatizer()\n",
        "  stpwords = stopwords.words('english')\n",
        "  lemmitized = [lemm.lemmatize(word) for word in words if word not in stpwords]\n",
        "  sent = ' '.join(lemmitized)\n",
        "  return sent"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMYJvXq9cGdT"
      },
      "source": [
        "#Apply preprocessing\n",
        "\n",
        "df['question1'] =df['question1'].apply(preprocess)\n",
        "df['question2'] =df['question2'].apply(preprocess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNPBrdHbVAgY"
      },
      "source": [
        "class Bert_QA (Dataset):\n",
        "    def __init__(self,q1,q2,label,max_length) :\n",
        "      self.q1  = q1\n",
        "      self.q2  = q2\n",
        "      self.label  = label\n",
        "      self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.q1)\n",
        "\n",
        "    def __getitem__ (self,item):\n",
        "      q1 = str(self.q1[item])\n",
        "      q2 = str(self.q2[item])\n",
        "\n",
        "      input = tokenizer.encode_plus (q1 ,q2  ,\n",
        "                                     add_special_tokens = True,\n",
        "                                     max_length = self.max_length,      \n",
        "                                     return_token_type_ids=False,\n",
        "                                     padding='max_length',\n",
        "                                     return_attention_mask=True,\n",
        "                                     truncation = True,\n",
        "                                     return_tensors='pt',)\n",
        "      ids = input['input_ids']\n",
        "      mask = input['attention_mask']\n",
        "\n",
        "      return {\n",
        "          'input_ids' : torch.tensor(ids,dtype=torch.long),\n",
        "          'attention_mask' : torch.tensor(mask,dtype=torch.long),\n",
        "          'target' : torch.tensor(int(self.label[item]),dtype=torch.float)\n",
        "\n",
        "      }"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed3a3N4XZaEw"
      },
      "source": [
        "#Dataset splitting into train , validation , test\n",
        "df_train, df_test = train_test_split(df, test_size=0.3, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.25, random_state=RANDOM_SEED)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvame8cAWgVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "669c2b5d-c49e-40a5-adb9-0281d4fbd8cf"
      },
      "source": [
        "#Check for Imbablanced labels\n",
        "sns.countplot(df.is_duplicate)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15cc4c4a90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHZ8bPRNZahV"
      },
      "source": [
        "def create_data_loader(df, max_len, batch_size):\n",
        "  ds = Bert_QA(\n",
        "    q1=df.question1.to_numpy(),\n",
        "    q2=df.question2.to_numpy(),\n",
        "    label=df.is_duplicate.to_numpy(),\n",
        "    max_length=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    drop_last=True\n",
        "  )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XbQ763hZlWS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c64507-d879-4a5b-ff60-6f2dc245e971"
      },
      "source": [
        "train_data_loader = create_data_loader(df_train, max_length, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, max_length, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, max_length, BATCH_SIZE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMn3e11WDQfH"
      },
      "source": [
        "#Model Archticture\n",
        "class Bert_model (nn.Module):\n",
        "  def __init__(self) :\n",
        "    super(Bert_model,self).__init__()\n",
        "    self.bert =  BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "    self.drop_layer = nn.Dropout(.25)\n",
        "    self.output = nn.Linear(self.bert.config.hidden_size-2,1)\n",
        "    self.cnn = nn.Conv1d(max_length,1,3)\n",
        "\n",
        "  def forward(self,input_ids,attention_mask):\n",
        "    o1,o2 = self.bert (input_ids =input_ids , attention_mask = attention_mask )\n",
        "    o1 = self.cnn(o1)\n",
        "    o1 = torch.flatten(o1, start_dim=1)\n",
        "    o1 = self.drop_layer(o1)\n",
        "    out = torch.sigmoid(self.output(o1))\n",
        "    return out"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRLLgW9BZ196"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Bert_model()\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gt0KD5EaCR5"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False, weight_decay=1e-5) #Optimizer with Regularization\n",
        "\n",
        "loss_fn = nn.BCELoss() #Loss Function"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5JC2EAaaL5n"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"target\"].to(device)\n",
        "\n",
        "    input_ids = input_ids.view(BATCH_SIZE,-1)\n",
        "    attention_mask = attention_mask.view(BATCH_SIZE,-1)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    targets = targets.unsqueeze(-1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(np.round(outputs.detach()) == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFDEnLw3aOtY"
      },
      "source": [
        "def eval_epoch(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"target\"].to(device)\n",
        "      input_ids = input_ids.view(BATCH_SIZE,-1)\n",
        "      attention_mask = attention_mask.view(BATCH_SIZE,-1)\n",
        "      \n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      targets = targets.unsqueeze(-1)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(np.round(outputs.detach()) == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w62oihQtaTuZ"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_epoch(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyQ9KvckH0Gd"
      },
      "source": [
        "plt.plot(history['train_loss'], label='train Loss')\n",
        "plt.plot(history['val_loss'], label='validation Loss')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}